#! /bin/bash
#~/.bashrc: executed by bash(1) for non-login shells.
# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)
# for examples
#
# ======================================================================================
# ======================= ~ DEFAULT UBUNTU BASHRC ~ ====================================
# ======================================================================================
#
# don't put duplicate lines or lines starting with space in the history.
# See bash(1) for more options
HISTCONTROL=ignoreboth

# append to the history file, don't overwrite it
shopt -s histappend

# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)
HISTSIZE=1000
HISTFILESIZE=2000

# check the window size after each command and, if necessary,
# update the values of LINES and COLUMNS.
shopt -s checkwinsize

# If set, the pattern "**" used in a pathname expansion context will
# match all files and zero or more directories and subdirectories.
#shopt -s globstar

# make less more friendly for non-text input files, see lesspipe(1)
[ -x /usr/bin/lesspipe ] && eval "$(SHELL=/bin/sh lesspipe)"

# set variable identifying the chroot you work in (used in the prompt below)
if [ -z "${debian_chroot:-}" ] && [ -r /etc/debian_chroot ]; then
    debian_chroot=$(cat /etc/debian_chroot)
fi

# set a fancy prompt (non-color, unless we know we "want" color)
case "$TERM" in
    xterm-color|*-256color) color_prompt=yes;;
esac

# uncomment for a colored prompt, if the terminal has the capability; turned
# off by default to not distract the user: the focus in a terminal window
# should be on the output of commands, not on the prompt
#force_color_prompt=yes

if [ -n "$force_color_prompt" ]; then
    if [ -x /usr/bin/tput ] && tput setaf 1 >&/dev/null; then
        # We have color support; assume it's compliant with Ecma-48
        # (ISO/IEC-6429). (Lack of such support is extremely rare, and such
        # a case would tend to support setf rather than setaf.)
        color_prompt=yes
    else
        color_prompt=
    fi
fi

if [ "$color_prompt" = yes ]; then
    PS1='${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ '
else
    PS1='${debian_chroot:+($debian_chroot)}\u@\h:\w\$ '
fi
unset color_prompt force_color_prompt

# If this is an xterm set the title to user@host:dir
case "$TERM" in
xterm*|rxvt*)
    PS1="\[\e]0;${debian_chroot:+($debian_chroot)}\u@\h: \w\a\]$PS1"
    ;;
*)
    ;;
esac

# enable color support of ls and also add handy aliases
if [ -x /usr/bin/dircolors ]; then
    test -r ~/.dircolors && eval "$(dircolors -b ~/.dircolors)" || eval "$(dircolors -b)"
    alias ls='ls --color=auto'
    #alias dir='dir --color=auto'
    #alias vdir='vdir --color=auto'

    alias grep='grep --color=auto'
    alias fgrep='fgrep --color=auto'
    alias egrep='egrep --color=auto'
fi

# colored GCC warnings and errors
#export GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01'

# some more ls aliases
alias ll='ls -alF'
alias la='ls -A'
alias l='ls -CF'

# Add an "alert" alias for long running commands.  Use like so:
#   sleep 10; alert
alias alert='notify-send --urgency=low -i "$([ $? = 0 ] && echo terminal || echo error)" "$(history|tail -n1|sed -e '\''s/^\s*[0-9]\+\s*//;s/[;&|]\s*alert$//'\'')"'

# Alias definitions.
# You may want to put all your additions into a separate file like
# ~/.bash_aliases, instead of adding them here directly.
# See /usr/share/doc/bash-doc/examples in the bash-doc package.
# shellcheck source=/dev/null
if [ -f /home/"$USER"/.bash_aliases ]; then
    . /home/"$USER"/.bash_aliases
fi

# enable programmable completion features (you don't need to enable
# this, if it's already enabled in /etc/bash.bashrc and /etc/profile
# sources /etc/bash.bashrc).
# shellcheck source=/dev/null
if ! shopt -oq posix; then
  if [ -f /usr/share/bash-completion/bash_completion ]; then
    . /usr/share/bash-completion/bash_completion
  elif [ -f /etc/bash_completion ]; then
    . /etc/bash_completion
  fi
fi
#
#
case $- in
    *i*) ;;
    *) return;;
esac
#
# ======================================================================================
# ============================ ~ CUSTOMIZE ME ~ ========================================
# ======================================================================================
#
# I highly encourage you to play with renaming functions and aliases to your liking.
# What you type and call should coincide with your internal monologues expectations. 
# Some of the functions like get.k3s and get.rke2 are redundant just to meet the expectations
# of my internal monologue when typing. You could just create a new function called get.product or 
# get.cli which expects you to pass in the name of the product k3s or rke2.
#
# ======================================================================================
# ================================ ~ CLUSTERS ~ ========================================
# ======================================================================================


# --- download k3s install.sh ---
function get.k3s() {
    curl https://get.k3s.io --output install-k3s.sh
    sudo chmod +x install-k3s.sh
}

# --- install k3s server or agent and run---
function go.k3s() {
    local VERSION="${1}"
    #local CHANNEL="${3:-testing}"
    #local TYPE="${4:-server}"
    sudo INSTALL_K3S_VERSION="$VERSION" INSTALL_K3S_EXEC=server ./install-K3s.sh
    #sudo INSTALL_"$PRODUCT"_VERSION="$VERSION" INSTALL_"$PRODUCT"_CHANNEL="$CHANNEL" INSTALL_"$PRODUCT"_EXEC="$TYPE" ./install-"$PRODUCT".sh
}

# --- download rke2 install.sh ---
function get.rke2() {
    curl https://get.rke2.io --output install-rke2.sh
    sudo chmod +x install-rke2.sh
}

# --- start rke2 systemctl service type ---
function go.rke2() {
    local TYPE="${1:-server}"
    sudo systemctl enable rke2-"$TYPE" --now
}

# --- print to console current config file ---
function get.figs() {
    local PRODUCT="${1:-k3s}"
    printf '=========== %s config =========== \n' "$PRODUCT"
    sudo cat /etc/rancher/"$PRODUCT"/config.yaml;
}

# --- restore previously saved config file (from void function) ---
function go.replay() {
    # after you've called void the tmp-confs directory is made with your previos config
    local PRODUCT="${1:-k3s}"
    sudo mkdir -p /etc/rancher/"$PRODUCT"/;
    sudo cp ~/tmp-confs/"$PRODUCT"-config.yaml /etc/rancher/"$PRODUCT"/config.yaml
}

# --- set KUBECONFIG environment variable ---
function set.kubefig() {
    local PRODUCT="${1:-k3s}"
    export KUBECONFIG=/etc/rancher/"$PRODUCT"/"$PRODUCT".yaml
    sudo chmod 644 /etc/rancher/"$PRODUCT"/"$PRODUCT".yaml
}

# --- quickly edit product config file ---
function conf() {
    local PRODUCT="${1:-k3s}"
    sudo vi /etc/rancher/"$PRODUCT"/config.yaml
}

# --- prints out node token ---
function get.token() {
    local PRODUCT="${1:-k3s}"
    sudo cat /var/lib/rancher/"$PRODUCT"/server/node-token
}

# --- killall uninstall all ---
function void() {
    # sudo systemctl list-units | grep -i -e k3s -e rke2 ??? find whats installed - then just remove those instead of trying all
    mkdir ~/tmp-confs/
    sudo cp /etc/rancher/k3s/config.yaml ~/tmp-confs/k3s-config.yaml
    sudo cp /etc/rancher/rke2/config.yaml ~/tmp-confs/rke2-config.yaml
    sudo /usr/local/bin/rke2-agent-killall.sh
    sudo /usr/local/bin/rke2-agent-uninstall.sh
    sudo /usr/local/bin/k3s-agent-killall.sh
    sudo /usr/local/bin/k3s-agent-uninstall.sh
    sudo /usr/local/bin/rke2-killall.sh
    sudo /usr/local/bin/rke2-uninstall.sh
    sudo /usr/local/bin/k3s-killall.sh
    sudo /usr/local/bin/k3s-uninstall.sh
    sudo /usr/bin/rke2-killall.sh
    sudo /usr/bin/rke2-uninstall.sh
    sudo /usr/bin/k3s-killall.sh
    sudo /usr/bin/k3s-uninstall.sh
    # consider rm -rf /var/lib/rancher/
}

# --- list binaries in directory from product install ---
function get.bins() {
    local PRODUCT="${1:-k3s}"
    ls /var/lib/rancher/"$PRODUCT"/data/current/bin/
    #consider local variable to find the embedded bin at known directory locations
    echo "/var/lib/rancher/k3s/data/current/bin OR /var/lib/rancher/rke2/data/current/bin"
}

# --- get performance profile from kubectl api ---
function get.pprof() {
    # note this requires enable-pprof=true in config.yaml
    local ARRAY=("profile" "symbol" "trace?seconds=8" "cmdline");
	for id in "${ARRAY[@]}"
		do
            curl --insecure https://localhost:6443/debug/pprof/"$id" > ~/"$id".pprof
		done
        #back on localhost or wherever GoLang is installed 
        # run $ go tool pprof GENERATED_FILENAME to run various commands on the files like .PNG etc
        # trace uses $ go tool trace trace-outputfile view refresher - https://github.com/k3s-io/k3s/pull/5527 /// https://pkg.go.dev/net/http/pprof
}
#
# ======================================================================================
# ================================== ~ SONOBUOY ~ =======================================
# ======================================================================================

# --- download sonobuoy ---
function get.sono() {
    sudo yum install wget
    wget https://github.com/vmware-tanzu/sonobuoy/releases/download/v0.56.10/sonobuoy_0.56.10_linux_amd64.tar.gz
    sudo tar -xzf sonobuoy_0.56.10_linux_amd64.tar.gz -C /usr/local/bin
}

# --- start sonobuoy e2e conformance tests ---
function go.sono() {
    local PRODUCT="${1:-k3s}"
    #sonobuoy run --wait --kubeconfig /etc/rancher/"$PRODUCT"/"$PRODUCT".yaml --plugin https://raw.githubusercontent.com/vmware-tanzu/sonobuoy-plugins/master/cis-benchmarks/kube-bench-plugin.yaml --plugin https://raw.githubusercontent.com/vmware-tanzu/sonobuoy-plugins/master/cis-benchmarks/kube-bench-master-plugin.yaml
    sonobuoy run --wait --kubeconfig /etc/rancher/"$PRODUCT"/"$PRODUCT".yaml --mode=certified-conformance
    #--kubernetes-version="$VERSION" --mode=certified-conformance
}

# --- view sonobuoy results ---
function sono.results() {
    local PRODUCT="${1:-k3s}"
    results=$(sonobuoy retrieve --kubeconfig /etc/rancher/"$PRODUCT"/"$PRODUCT".yaml)
    sonobuoy results "$results"    
}

# --- removes all docker images from the local cache ---
function void.docker() {
    docker rmi "$(docker images -a -q)"
}
# ======================================================================================
# ================================== ~ RANCHER ~ =======================================
# ======================================================================================

# --- requires helm --- REWRITE WITH INSTALL.SH IF CHECKS FOR HELM --- https://github.com/k3s-io/k3s/blob/master/install.sh
function make.ranch() {
    echo "need to adjust this to detect which binaries are already installed - modify the path based on their presences"
    echo "figure out all the steps here to setup a local rancher node to add downstream clusters to"
    sudo apt update && sudo apt upgrade -y
    wait
    helm repo add rancher-latest https://releases.rancher.com/server-charts/latest
    kubectl create namespace cattle-system
    helm repo add jetstack https://charts.jetstack.io
    helm repo update
    wait
    helm install cert-manager jetstack/cert-manager -n cert-manager --create-namespace --version v1.5.1
    wait
    echo "checking cert-manager pods.... "
    kubectl get pods -n cert-manager
    wait
    kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.5.1/cert-manager.crds.yaml
    wait
    helm install rancher rancher-latest/rancher -n cattle-system --set hostname=break.qa.web --set rancherImageTag=v2.6.9 --version=v2.6.9 
    wait
    watch -n 7 kubectl -n cattle-system rollout status deploy/rancher
    kubectl port-forward "$(kubectl get pods --selector "app.kubernetes.io/name=traefik" --output=name -A)" 9000:9000 -A
}

# --- gets rancher password and dashboard url ---
function get.ranch() {
    echo https://break.qa/dashboard/?setup="$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}')"
    kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}{{ "\n" }}'
}

# --- forward the rancher ui to all interfaces ---
function forward.ranch() {
    kubectl port-forward -n cattle-system svc/rancher 9944:443 --address='0.0.0.0'
}
#
#
# ======================================================================================
# ================================== ~ CONFIGURATIONS ~ ================================
# ======================================================================================

# --- set default configuration to edit ---
function set.figs() {
    local PRODUCT="${1:-k3s}"
    sudo mkdir -p /etc/rancher/"$PRODUCT"/;
    #sudo cat <<EOF >> "$PRODUCT"-config.yaml
    cat <<EOF >> "$PRODUCT"-config.yaml
write-kubeconfig-mode: 644
debug: true
token: epicsalsa
cni: cilium
server:

profile: cis-1.6
selinux: true
#protect-kernel-defaults: true
#cluster-init: true

##EDIT these
node-ip: $(hostname -I)
#node-external-ip: IPV4,IPV6

##KUBELET ARGS 
#kubelet-arg:
#  - alsologtostderr=true
#  - feature-gates=MemoryManager=true
#  - kube-reserved=cpu=400m,memory=1Gi
#  - system-reserved=cpu=400m,memory=1Gi
#  - alsologtostderr=true
#  - memory-manager-policy=Static
#  - reserved-memory=0:memory=2Gi

##SNAPSHOTS
#snapshot-compress: true
#etcd-snapshot-retention: 18
#etcd-snapshot-schedule-cron: 0 0,5,10,15,20,22 * * *
#etcd-snapshot-compress: true

##VSPHERE
#private-registry: "/etc/rancher/rke2/registries.yaml"
#cloud-provider-name: "rancher-vsphere"
#cloud-provider-config: /home/rancher/vsphere.conf

#pod-security-admission-config-file: "/etc/rancher/rke2/base-pss.yaml"
#enable-pprof: true
#secrets-encryption: true
#kube-proxy-arg: "proxy-mode=ipvs"

##ETCD S3 CONFIG
#etcd-s3: true
#etcd-s3-bucket: "YOUR_BUCKET_NAME"
#etcd-s3-folder: "foldername ie 123 or 124 or 125"
#etcd-s3-region: "YOUR_REGION"
#etcd-s3-endpoint: "s3.us-west-2.amazonaws.com"
#etcd-s3-access-key: "YOUR_ACCESS_KEY"
#etcd-s3-secret-key: "YOUR_SECRET_KEY"

##DUALSTACK
#cluster-cidr: 10.42.0.0/16,2001:cafe:42:0::/56
#service-cidr: 10.43.0.0/16,2001:cafe:42:1::/112

#flannel-ipv6-masq: true
#disable: rke2-ingress-nginx

## SPLIT ROLES

##--etcd-only---
#disable-apiserver: true
#disable-controller-manager: true
#disable-scheduler: true
#node-taint:
#  - node-role.kubernetes.io/etcd:NoExecute

##--etcd-cp---
#node-taint:
#  - node-role.kubernetes.io/control-plane:NoSchedule
#  - node-role.kubernetes.io/etcd:NoExecute

##--etcd-worker---
#disable-apiserver: true
#disable-controller-manager: true
#disable-scheduler: true

##--cp-only---
#disable-etcd: true
#node-taint:
#  - node-role.kubernetes.io/control-plane:NoSchedule

##--cp-worker---
#disable-etcd: true

EOF
    sudo cp "$PRODUCT"-config.yaml /etc/rancher/"$PRODUCT"/config.yaml;
}

# --- set registries to look for bci hardened images ---
function set.registries() {
    cat <<'EOF' >> registries.yaml
    mirrors:
    docker.io:
        rewrite:
        "^rancher/hardened-etcd(.*)": "bcibase/hardened-etcd$1"
        "^rancher/hardened-kubernetes(.*)": "bcibase/hardened-kubernetes$1"
        "^rancher/hardened-rke2-runtime(.*)": "bcibase/hardened-rke2-runtime$1"
        "^rancher/nginx-ingress-controller(.*)": "bcibase/nginx-ingress-controller$1"
        "^rancher/nginx-ingress-controller-chroot(.*)": "bcibase/nginx-ingress-controller-chroot$1"
        "^rancher/hardened-calico(.*)": "bcibase/hardened-calico$1"
        "^rancher/hardened-sriov-network-resources-injector(.*)": "bcibase/hardened-sriov-network-resources-injector$1"
        "^rancher/hardened-k8s-metrics-server(.*)": "bcibase/hardened-k8s-metrics-server$1"
        "^rancher/hardened-sriov-network-webhook(.*)": "bcibase/hardened-sriov-network-webhook$1"
        "^rancher/hardened-sriov-network-operator(.*)": "bcibase/hardened-sriov-network-operator$1"
        "^rancher/hardened-sriov-network-device-plugin(.*)": "bcibase/hardened-sriov-network-device-plugin$1"
        "^rancher/hardened-flannel(.*)": "bcibase/hardened-flannel$1"
        "^rancher/hardened-crictl(.*)": "bcibase/hardened-crictl$1"
        "^rancher/hardened-ib-sriov-cni(.*)": "bcibase/hardened-ib-sriov-cni$1"
        "^rancher/hardened-runc(.*)": "bcibase/hardened-runc$1"
        "^rancher/hardened-rke2-cloud-provider(.*)": "bcibase/hardened-rke2-cloud-provider$1"
        "^rancher/hardened-cni-plugins(.*)": "bcibase/hardened-cni-plugins$1"
        "^rancher/hardened-dns-node-cache(.*)": "bcibase/hardened-dns-node-cache$1"
        "^rancher/hardened-containerd(.*)": "bcibase/hardened-containerd$1"
        "^rancher/hardened-cluster-autoscaler(.*)": "bcibase/hardened-cluster-autoscaler$1"
        "^rancher/hardened-coredns(.*)": "bcibase/hardened-coredns$1"
        "^rancher/hardened-multus-cni(.*)": "bcibase/hardened-multus-cni$1"
        "^rancher/hardened-whereabouts(.*)": "bcibase/hardened-whereabouts$1"
EOF
    sudo cp registries.yaml /etc/rancher/rke2/registries.yaml
}

# --- vsphere in tree ---
function set.vsphere() {
    cat <<'EOF' >> vsphere.conf
# vsphere.conf
Name:         vsphere-cloud-config
Namespace:    kube-system
Labels:       app.kubernetes.io/managed-by=Helm
              component=rancher-vsphere-cpi-cloud-controller-manager
              vsphere-cpi-infra=config
Annotations:  meta.helm.sh/release-name: rancher-vsphere-cpi
              meta.helm.sh/release-namespace: kube-system

Data
====
vsphere.yaml:
----
# Global properties in this section will be used for all specified vCenters unless overriden in VirtualCenter section.

[Global]
datacenters = "YOUR_DATA_CENTER"
insecure-flag = "1"
user = "YOUR_USER_NAME"
password = "YOUR_PASSWORD"
server = "YOUR_SERVER_NAME"
port = "YOUR_PORT"
secret-namespace: "kube-system"
secret-name: "vsphere-cpi-creds"
 
[VirtualCenter "YOUR_SERVER_NAME"]
user = "YOUR_USER_NAME"
password = "YOUR_PASSWORD"
port = "YOUR_PORT"
datacenters = "YOUR_DATA_CENTER" 

[Workspace]
server = "YOUR_SERVER_NAME"
datacenters = "YOUR_DATA_CENTER"
default-datastore = "YOUR_DATA_STORE_URL"
resourcepool-path = "YOUR_RESOURCE_POOL_PATH"
folder = "YOUR_USERNAME"
EOF
}

# --- adding custom vsphere-values to the server manifests directory ---
function set.vspheremanifests() {
    sudo mkdir -p /var/lib/rancher/rke2/server/manifests;
    cat <<'EOF' >> vsphere-values.yaml
# /var/lib/rancher/rke2/server/manifests/vsphere-values.yaml
apiVersion: helm.cattle.io/v1
kind: HelmChartConfig
metadata:
  name: rancher-vsphere-cpi
  labels:
  namespace: kube-system
spec:
  valuesContent: |-
    vCenter:
      host: "YOUR_HOSTNAME"
      datacenters: "YOUR_DATA_CENTER"
      username: "YOUR_USERNAME"
      password: "YOUR_PASSWORD"
      credentialsSecret:
        generate: true
      labels:
        generate: true
        zone: "test-zone"
        region: "test-region"
    cloudControllerManager:
      nodeSelector:
        node-role.kubernetes.io/control-plane: "true"
---
apiVersion: helm.cattle.io/v1
kind: HelmChartConfig
metadata:
  name: rancher-vsphere-csi
  namespace: kube-system
spec:
  valuesContent: |-
    vCenter:
      host: "YOUR_HOSTNAME"
      datacenters: "YOUR_DATA_CENTER"
      username: "YOUR_USERNAME"
      password: "YOUR_PASSWORD"
      clusterId: "YOUR_NODE_HOSTNAME"
      configSecret:
        configTemplate: |
         [Global]
         cluster-id = {{ required ".Values.vCenter.clusterId must be provided" (default .Values.vCenter.clusterId .Values.global.cattle.clusterId) | quote }}
         user = {{ .Values.vCenter.username | quote }}
         password = {{ .Values.vCenter.password | quote }}
         port = {{ .Values.vCenter.port | quote }}
         insecure-flag = {{ .Values.vCenter.insecureFlag | quote }}
         [VirtualCenter {{ .Values.vCenter.host | quote }}]
         datacenters = {{ .Values.vCenter.datacenters | quote }}
         [Labels]
         zone = "test-zone"
         region = "test-region"
    storageClass:
      datastoreURL: "YOUR_DATA_STORE_URL"
    csiController:
      nodeSelector:
        node-role.kubernetes.io/control-plane: "true"
EOF
    sudo cp vsphere-values.yaml /var/lib/rancher/rke2/server/manifests/vsphere-values.yaml
    cat <<'EOF' >> persistentVolume.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: claim1
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: vsphere-csi-sc
  resources:
    requests:
      storage: 1Gi
EOF
    cat <<'EOF' >> useVolume-Workload.yaml
apiVersion: "v1"
kind: "Pod"
metadata:
  name: "basic"
  labels:
    name: "basic"
spec:
  containers:
    - name: "basic"
      image: ranchertest/mytestcontainer:unprivileged
      ports:
        - containerPort: 8080
          name: "basic"
      volumeMounts:
        - mountPath: "/data"
          name: "pvol"
  volumes:
    - name: "pvol"
      persistentVolumeClaim:
        claimName: "claim1"
EOF
}

# --- creates a basic pod security standards file for k3s or rke2---
function set.pss() {
    local PRODUCT="${1:k3s}"
    cat <<'EOF' >> base-pss.yaml
apiVersion: apiserver.config.k8s.io/v1
kind: AdmissionConfiguration
plugins:
- name: PodSecurity
  configuration:
    apiVersion: pod-security.admission.config.k8s.io/v1beta1
    kind: PodSecurityConfiguration
    defaults:
      enforce: "baseline"
      enforce-version: "latest"
    exemptions:
      usernames: []
      runtimeClasses: []
      namespaces: [kube-system, cis-operator-system, tigera-operator]
EOF
    sudo cp base-pss.yaml /etc/rancher/"$PRODUCT"/base-pss.yaml
}

# --- label nodes server and agent respectively for suc upgrade to run correctly ---
function set.labels() {
    local PRODUCT="${1:-k3s}"
    kubectl label node -l node-role.kubernetes.io/master==true "$PRODUCT"-upgrade=server 
    kubectl label node -l node-role.kubernetes.io/master!=true "$PRODUCT"-upgrade=agent
}

# --- print info logs when debug is enabled ---
function get.logs() {
    local PRODUCT="${1:-k3s}"
    local TYPE="${2:-server}"
    sudo journalctl -xeu "$PRODUCT"-"$TYPE" -o json-pretty | grep -i -e message -e info
    # experiment with de-cluttering the normal pings to tunnel server etc
}

# --- rotate and vacuum logs ---
function clean.logs() {
    sudo journalctl --rotate && sudo journalctl --vacuum-time=1s
}

# --- helper functions for logs ---
function get.ulog() {
    sudo cat /var/log/ulog/syslogemu.log
}

# --- get systemctl status ---
function get.status() {
    local PRODUCT="${1:-k3s}"
    sudo systemctl status "$PRODUCT"
}
#
# ======================================================================================
# ================================== ~ NETWORK TESTS ~ =================================
# ======================================================================================

# --- quickly list etcd cluster members ---
function get.etcd() {
    local PRODUCT="${1:-rke2}"
     sudo ETCDCTL_API=3 etcdctl \
    --cert /var/lib/rancher/"$PRODUCT"/server/tls/etcd/server-client.crt \
    --key /var/lib/rancher/"$PRODUCT"/server/tls/etcd/server-client.key \
    --endpoints https://127.0.0.1:2379 \
    --cacert /var/lib/rancher/"$PRODUCT"/server/tls/etcd/server-ca.crt \
    member list -w table
    ##   https://etcd.io/docs/v3.5/tutorials/how-to-deal-with-membership/
}

# --- quickly list manifest files ---
function get.manifests() {
    local PRODUCT="${1:-k3s}"
    sudo bash -c 'ls --color=auto /var/lib/rancher/"$PRODUCT"/server/manifests/'
}

# --- quickly exec a shell in a pod ---
function k.tty() {
    local namespace="{$1}"
    local podTarget="{$2}"
    kubectl exec -n "$namespace" --stdin --tty "$podTarget" -- /bin/bash
}

# --- quickly list any pods in any namespace in error or crashloop status ---
function get.podcrash() {
    kubectl get pods -A | awk '$3 ~/CrashLoopBackOff/ {print $1 $3}'
    kubectl get pods -A | awk '$3 ~/Error/ {print $1 $3}'
}


# --- quickly list node taints ---
function get.taints() {
    kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints
}
#

# --- check rke2 crictl images and versions ---
function get.images() {
    local PRODUCT="${1:-k3s}"
    case "$PRODUCT" in
    rke2) sudo /var/lib/rancher/"$PRODUCT"/bin/crictl --config /var/lib/rancher/"$PRODUCT"/agent/etc/crictl.yaml ps
          sudo /var/lib/rancher/"$PRODUCT"/bin/crictl --config /var/lib/rancher/"$PRODUCT"/agent/etc/crictl.yaml images
        ;;
    k3s) 
        sudo k3s crictl ps
        sudo k3s crictl img ls
        ;;
    esac
}

# --- checks for the bci tag in rke2 containerd images ---
function get.bci() {
    local PRODUCT="${1:-rke2}"
    case "$PRODUCT" in
    rke2) mapfile -t ARRAY < <(sudo /var/lib/rancher/rke2/bin/crictl -r unix:///run/k3s/containerd/containerd.sock images | awk 'NR>1{print $3}');
        for id in "${ARRAY[@]}"
            do
                echo "The ID: $id "
                sudo /var/lib/rancher/rke2/bin/crictl -r unix:///run/k3s/containerd/containerd.sock inspecti "$id" | grep bci
            done
        ;;
    k3s) mapfile -t ARRAY < <(sudo k3s crictl -r unix:///run/k3s/containerd/containerd.sock images | awk 'NR>1{print $3}');    
        for id in "${ARRAY[@]}"
         do 
            echo "The ID: $id "
            sudo k3s crictl -r unix:///run/k3s/containerd/containerd.sock inspecti "$id" | grep bci 
        done
    ;;
    esac
}

# --- gets the ips of the pods in the provided namespace ---
function get.podips() {
    local namespace="${1:-kube-system}"
    #bash doesn't like the -o jsonpath straight into an array so we have to do this.
    kubectl get pods -n "$namespace" -o jsonpath='{range .items[*]}{.metadata.name}{"    "}{.status.podIP}{"\n"}{end}'
    #fortunately we can still awk and print the needed variables - this isn't streamlined to automatically call ping on the pod ips.
    # get.podips | awk '{print $2}'
    # kubectl exec -n kube-system -it $pod -- ping -c 5 $ip
    # my first command before jsonpath was somewhat more functional at least
    # for pod in $(kubectl get pods -A | awk 'NR>1{print $2}'); do   for ip in $(kubectl get pods -n kube-system $pod -o yaml | grep -e "podIP: " | awk '{print $2}'); do echo $pod "\n";  kubectl exec -n kube-system -it $pod -- ping -c 5 $ip;   done; done
}

# --- this is a work in progress but it gets the ips on the pods and pings the adjacent pods to check network connectivity this will likely go away in this form ---
function ping.pods() {
    for pod in $(kubectl get pods -A | awk 'NR>1{print $2}'); do   for ip in $(kubectl get pods -n kube-system "$pod" -o yaml | grep -e "podIP: " | awk '{print $2}'); do printf '%s' "$pod \n";  kubectl exec -n kube-system -it "$pod" -- ping -c 5 "$ip";   done; done
}

# --- less typing get ids of containers ---
function get.containerids() {
    sudo ctr --address /run/k3s/containerd/containerd.sock --namespace k8s.io c ls
}

# --- less typing get containerd version ---
function get.contd() {
    sudo /var/lib/rancher/rke2/bin/containerd --version
}

# --- take an adhoc etcd snapshot with less typing ---
function take.etcd() {
    local FOLDER="${1:-123}"
    sudo rke2 etcd-snapshot --s3 --s3-bucket=YOUR_BUCKET --s3-folder="$FOLDER" --s3-region=YOUR_REGION --s3-access-key=YOUR_ACCESS_KEY --s3-secret-key=YOUR_SECRET_KEY
}
# ======================================================================================
# =========================== ~ SOMEDAY FUNCTIONS ~ ====================================
# ======================================================================================


# --- curl to pull down patch tests kubectl assert statements ---
function get.tests() {
    git clone https://github.com/rancher/ecm-distro-tools.git && cd ecm-distro-tools/qa/ || return
}

# --- future home of a function to post or redirect kubectl api json results to an http endpoint ---
function post.tests() {
    #curl -X POST -H "Content-Type: application/json" -d '{"json":"json"}' http://localhost:8080
    #local YOUR_PUB_KEY="${1:-$HOME/.ssh/id_rsa.pub}"
    echo "curl -X POST github.api thing"
    kubectl cluster-info dump > dump.json
}
#
# ======================================================================================
# =========================== ~ CONFIGURATIONS ~ =======================================
# ======================================================================================

# --- generates a github comment template to cat to console and copy to paste in github for the issue ---
function get.report() {
    local PRODUCT="${1:-k3s}"
    cat << EOF >> validation_template.md
<!-- Thanks for using this template. Comment like this will be hidden. Enjoy! -->
<!-- Make sure you remove any sensitive information and change IPs before sharing. -->
##Environment Details
COMMIT= (echo $COMMIT)
VERSION= (echo $VERSION)

*Infrastructure*
- [X] Cloud
- [ ] Hosted 

*Node(s) CPU architecture, OS, and Version:*

$(uname -rpos) 
$(grep /etc/os-release -i -e pretty)
 
*Cluster Configuration:*

$(kubectl get nodes) 

*Config.yaml:*

$(sudo cat /etc/rancher/"$PRODUCT"/config.yaml)

<details>
<summmary><h4> YOUR_REPRODUCED_RESULTS_HERE </h4></summary>

<!-- Provide the command to install "$PRODUCT" -->

"$" curl https://get.$PRODUCT.io --output install-"$PRODUCT".sh
"$" sudo chmod +x install-"$PRODUCT".sh
"$" sudo groupadd --system etcd && sudo useradd -s /sbin/nologin --system -g etcd etcd
"$" sudo modprobe ip_vs_rr
"$" sudo modprobe ip_vs_wrr
"$" sudo modprobe ip_vs_sh
"$" sudo printf "on_oovm.panic_on_oom=0 \nvm.overcommit_memory=1 \nkernel.panic=10 \nkernel.panic_ps=1 \nkernel.panic_on_oops=1 \n" > ~/60-rke2-cis.conf
"$" sudo cp 60-rke2-cis.conf /etc/sysctl.d/
"$" sudo systemctl restart systemd-sysctl


"$(history)"

**Results:**

</details>

<details>
<summmary><h4> YOUR_VALIDATION_RESULTS_HERE </h4></summary>
**Validated with **
 
## Validation Steps
 
- Install "$PRODUCT":
 
 
**Additional context / logs:**
</details>  
EOF
}
#

# --- creates etcduser account on system and also kernel params in rke2 ---
function make.etcduser() {
    sudo groupadd --system etcd && sudo useradd -s /sbin/nologin --system -g etcd etcd
}

# --- set kernel params for hardening ---
function set.harden() {
    local PRODUCT="${1:-k3s}"
    case "$PRODUCT" in
    rke2) printf "on_oovm.panic_on_oom=0 \nvm.overcommit_memory=1 \nkernel.panic=10 \nkernel.panic_ps=1 \nkernel.panic_on_oops=1 \nkernel.keys.root_maxbytes=25000000" > ~/60-rke2-cis.conf
          sudo cp 60-rke2-cis.conf /etc/sysctl.d/
          sudo sysctl -p /etc/sysctl.d/60-rke2-cis.conf
            ;;
    k3s) printf "on_oovm.panic_on_oom=0 \nvm.overcommit_memory=1 \nkernel.panic=10 \nkernel.panic_ps=1 \nkernel.panic_on_oops=1 \nkernel.keys.root_maxbytes=25000000" > ~/90-kubelet.conf
         sudo cp 90-kubelet.conf /etc/sysctl.d/
         sudo sysctl -p /etc/sysctl.d/90-kubelet.conf
            ;;
    esac
    sudo modprobe ip_vs_rr
    sudo modprobe ip_vs_wrr
    sudo modprobe ip_vs_sh
    wait
    sudo systemctl restart systemd-sysctl
}

# --- create arbitrary nats server config ---
function set.nats() {
cat <<'EOF' >> nats.conf
port: 4222
net: '0.0.0.0'
authorization: {
  users: [
    {user: "k3s", password: "k3smighty"},
    {user: "rke2", password: "rke2mighty"}
  ]
}
EOF
sudo mkdir -p /srv/nats/
sudo cp nats-config.yaml /srv/nats/nats.conf
cat <<'EOF' >> nats.service
[Unit]
Description=NATS jetstream messaging server

[Service]
ExecStart=/usr/bin/nats-server -js -c /srv/nats/nats.config
User=nats
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF
sudo cp nats.service /etc/systemd/system/nats.service
sudo adduser --system --group --no-create-home --shell /bin/false nats
sudo systemctl enable nats --now
}

# ======================================================================================
# =========================== ~ GET TOOLS ~ ============================================
# ======================================================================================

# --- helper to print functions in this file ---
function get.help() {
    local INFO="${1:-function}"
    local NO_OF_LINES="${2:-6}"
    grep ~/.bashrc -i -e "$INFO" -A "$NO_OF_LINES"
}

# --- install helm to the node ---
function get.helm() {
    sudo curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
    sudo chmod +x get_helm.sh
    sudo ./get_helm.sh
}

# --- install docker ---
function get.docker() {
    curl -fsSL https://get.docker.com -o get-docker.sh && sudo chmod +x get-docker.sh
    sudo ./get-docker.sh
    wait
    sudo systemctl enable docker --now
}

# --- install wireguard ---
function get.wireguard() {
    printf "use your package manager to update && upgrade, then install wireguard \n note there are more steps to get wireguard working on SLES and SLEM"
}

# --- install etcdctl ---
function get.etcdctl() {
    local ETCD_VER=v3.5.0
    # choose either URL
    # GOOGLE_URL=https://storage.googleapis.com/etcd
    GITHUB_URL=https://github.com/etcd-io/etcd/releases/download
    DOWNLOAD_URL=${GITHUB_URL}

    rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz
    rm -rf /tmp/etcd-download-test && mkdir -p /tmp/etcd-download-test
    curl -L ${DOWNLOAD_URL}/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -o /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz
    tar xzvf /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz -C /tmp/etcd-download-test --strip-components=1
    rm -f /tmp/etcd-${ETCD_VER}-linux-amd64.tar.gz
    /tmp/etcd-download-test/etcd --version
    /tmp/etcd-download-test/etcdctl version
    /tmp/etcd-download-test/etcdutl version
    sudo cp /tmp/etcd-download-test/etcdctl /usr/bin/etcdctl
    etcdctl version
}

# --- install zerotier vpn ---
function get.zt() {
    curl -s https://install.zerotier.com | sudo bash
    wait
    sudo zerotier-cli join YOUR_ZT_NETWORK_ID
}

# --- install nats.io ---
function get.nats() {
    wget https://github.com/nats-io/nats-server/releases/download/v2.8.2/nats-server-v2.8.2-linux-amd64.tar.gz
    sudo tar -zxf nats-server-v2.8.2-linux-amd64.tar.gz
    sudo cp nats-server-v2.8.2-linux-amd64/nats-server /usr/bin/
    nats-server -v
}

# --- install krew plugin for kubectl ---
function get.krew() {
    # check for git installed
    (
  set -x; cd "$(mktemp -d)" &&
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &&
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &&
  KREW="krew-${OS}_${ARCH}" &&
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &&
  tar zxvf "${KREW}.tar.gz" &&
  ./"${KREW}" install krew
)
}

# --- install krew plugin for kubectl ---
function get.kuttl() {
    kubectl krew install kuttl
}
# ======================================================================================
# ================================== ~ CAPTAINS ~ ======================================
# ======================================================================================

# --- check CI for releases ---
function get.ci() {
    #requires drone logins :/ 
    printf "https://drone-publish.rancher.io/rancher/rke2  or https://drone-publish.k3s.io/k3s-io/k3s"
}

# --- check DockerHub system agent installers and upgrade images ---
function get.artifacts() {
    #requires jq
    local PRODUCT="${1:-k3s}"
    local BRANCH="${2:-v1.22}"
        printf "===== System Agent Installers ===== \n"
        curl -L -s "https://registry.hub.docker.com/v2/repositories/rancher/system-agent-installer-${PRODUCT}/tags?page_size=300" | jq -r ".results[].name" | sort --version-sort | grep -i -e "$BRANCH" | tail -n 5 # > system-agent-installers.txt
        printf "===== Upgrade Images ===== \n"
        curl -L -s "https://registry.hub.docker.com/v2/repositories/rancher/${PRODUCT}-upgrade/tags?page_size=300" | jq -r ".results[].name" | sort --version-sort | grep -i -e "$BRANCH" | tail -n 5 #  > upgrade-images.txt
        printf '===== %s Images ===== \n' "$PRODUCT"
    case "$PRODUCT" in
    rke2)
        curl -s -H "Accept: application/vnd.github+json" https://api.github.com/repos/rancher/rke2/releases | jq '.[].tag_name' | sort --version-sort | grep -i -e "$BRANCH" | tail -n 1
        # diff --color -s --suppress-common-lines system-agent-installers.txt upgrade-images.txt
    ;;
    k3s)
        curl -s -H "Accept: application/vnd.github+json" https://api.github.com/repos/k3s-io/k3s/releases | jq '.[].tag_name' | sort --version-sort | grep -i -e "$BRANCH" | tail -n 1
        # diff --color -s --suppress-common-lines system-agent-installers.txt upgrade-images.txt
    ;;
    esac
}

# --- check for upgrade images in 


# ======================================================================================
# ================================== ~ GITHUB ~ =======================================
# ======================================================================================

# --- list issues in the github repos using the gh cli --- 
 function ghls() {
	local PRODUCT="${1:-k3s}"
    local USER="${2:-VestigeJ}"
    case $PRODUCT in
    qa) gh issue ls -R rancher/qa-tasks -a "$USER" ;;
	rke2) gh issue ls -R rancher/rke2 -a "$USER" ;;
	k3s) gh issue ls -R k3s-io/k3s -a "$USER" ;;
	na)
	  printf "K3S-ISSUES---------------------------------------"
	  gh issue ls -R k3s-io/k3s 
	  printf "\nRKE2-ISSUES------------------------------------"
	  gh issue ls -R rancher/rke2
      printf "\nQA-ISSUES---------------------------------------"
      gh issue ls -R rancher/qa-tasks
	  ;;
	esac
	}

# --- get github issue comments ---
 function ghcom() {
	local PRODUCT="${1:-k3s}"	
	local ISSUE="${2}"
    case $PRODUCT in
	rke2)
	  gh issue view -c "$ISSUE" -R rancher/rke2
	  ;;	
	k3s)
	  gh issue view -c "$ISSUE" -R k3s-io/k3s
	  ;;
    qa)
      gh issue view -c "$ISSUE" -R rancher/qa-tasks
      ;;
	esac
	}

# --- list issues closed in the last n days for the milestone ---
function ghclosed() {
    local PRODUCT="${1:-k3s}"
    local days="${2:-7}"
    local date
    date=$(date -v -"$days"d +%F)
    local MILESTONE="${3:-v1.25.3+k3s1}"
    case $PRODUCT in
    rke2)
      gh search issues --repo rancher/rke2 --closed \>"$date" --milestone "$MILESTONE"
      ;;
    k3s)
        gh search issues --repo k3s-io/k3s --closed \>"$date" --milestone "$MILESTONE"
        ;;
    qa)
        gh search issues --repo rancher/qa-tasks --closed \>"$date"
        ;;
    esac
    }

# --- list issues in milestone ---
function ghmile() {
    local MILESTONE="${1}"
    local PRODUCT="${2:-k3s}"
    case $PRODUCT in
    rke2)
        gh issue list --milestone "$MILESTONE" -R rancher/rke2
        ;;
    k3s)
        gh issue list --milestone "$MILESTONE" -R k3s-io/k3s
        ;;
    esac
}

# ======================================================================================
# ================================== ~ ALIASES ~ =======================================
# ======================================================================================
#
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/var/lib/rancher/k3s/bin:/var/lib/rancher/rke2/bin:/usr/local/bin/go/bin:/opt/rke2/bin/:${HOME}/.krew/bin
alias ll="ls -lahr "
alias eventz="kubectl get events -A "
alias k="kubectl "
alias kl="kubectl logs "
alias kg="kubectl get "
alias kgs="kubectl get svc "
alias kge="kubectl get endpoints "
alias kgn="kubectl get nodes "
alias kgp="kubectl get pods "
alias kga="kubectl get all -A -o wide "
alias w2="watch -n 3 "
alias sono="sonobuoy "
alias kd="kubectl describe "
alias srz="source ~/.bashrc"
#
cat << "EOF"
--------------------------------
--------------@@@@--------------
--------------@@@@--------------█████████████████████████████████████
--------------@@@@--------------██,,,████,,,,█,,,,,,,,,████,,,,,,,███
--------------@@@@--------------██,,,██,,,,████████,,,,██,,,██████,,█
--------------@@@@--------------██,,,,,,,███████,,,,███████,,,███████
--------------------------------██,,,,,,,,██████████,,,███████,,,,███
----------@@&-----&@@-----------██,,,███,,,███,,,███,,,█,,███████,,,█
-------@@@@@@----&@@@@@@--------██,,,████,,,,██,,,,,,,████,,,,,,,,███
---@@@@@@@-----------@@@@@@@----█████████████████████████████████████
---@@%-------------------&@@----
--------------------------------             QA-Toolbox
--------------------------------
EOF
