#! /bin/sh
#~/.bashrc: executed by bash(1) for non-login shells.
# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)
# for examples
#
# ======================================================================================
# ======================= ~ DEFAULT UBUNTU BASHRC ~ ====================================
# ======================================================================================

# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)
HISTSIZE=1000
HISTFILESIZE=2000

# make less more friendly for non-text input files, see lesspipe(1)
[ -x /usr/bin/lesspipe ] && eval "$(SHELL=/bin/sh lesspipe)"

# set variable identifying the chroot you work in (used in the prompt below)
if [ -z "${debian_chroot:-}" ] && [ -r /etc/debian_chroot ]; then
    debian_chroot=$(cat /etc/debian_chroot)
fi

# set a fancy prompt (non-color, unless we know we "want" color)
TERM=xterm-256color
case "${TERM}" in
    xterm-color|*-256color) color_prompt=yes;;
esac

force_color_prompt=yes
if [ -n "$force_color_prompt" ]; then
    if [ -x /usr/bin/tput ] && tput setaf 1 2>&/dev/null; then
        # We have color support; assume it's compliant with Ecma-48
        # (ISO/IEC-6429). (Lack of such support is extremely rare, and such
        # a case would tend to support setf rather than setaf.)
        color_prompt=yes
    else
        color_prompt=
    fi
fi

if [ "$color_prompt" = yes ]; then
    PS1='${debian_chroot:+($debian_chroot)}\[\033[01;32m\]\u@\h\[\033[00m\]:\[\033[01;34m\]\w\[\033[00m\]\$ '
else
    PS1='${debian_chroot:+($debian_chroot)}\u@\h:\w\$ '
fi
unset color_prompt force_color_prompt

# If this is an xterm set the title to user@host:dir
case "${TERM}" in
xterm*|rxvt*)
    PS1="\[\e]0;${debian_chroot:+($debian_chroot)}\u@\h: \w\a\]$PS1"
    ;;
*)
    ;;
esac

# enable programmable completion features
# shellcheck disable=SC3044
if ! shopt -oq posix; then
  if [ -f /usr/share/bash-completion/bash_completion ]; then
    # shellcheck source=/dev/null
    . /usr/share/bash-completion/bash_completion
  elif [ -f /etc/bash_completion ]; then
    # shellcheck source=/dev/null
    . /etc/bash_completion
  fi
fi
#
case $- in
    *i*) ;;
    *) return;;
esac
#
# ======================================================================================
# ============================ ~ CUSTOMIZE ME ~ ========================================
# ======================================================================================
#
# I highly encourage you to play with renaming functions and aliases to your liking.
# What you type and call should coincide with your internal monologues expectations. 
# Some of the functions like get.k3s and get.rke2 are redundant just to meet the expectations
# of my internal monologue when typing. You could just create a new function called get.product or 
# get.cli which expects you to pass in the name of the product k3s or rke2.

# --- stolen from libstd-ecm.sh ---
# cmd_check checks if the command output
# passed in is empty or not. If it is then
# we print an error containing the missing
# command and exit.
# __cmd_check() {
    
# }

# --- the error handling in __cmd_check exits the bash session if it fails and it doesn't correctly print the binary name that is missing. ---
has_bin() {
    bin="$(command -v "$1")"
    if [ -z "$bin" ]; then 
        echo "error: ${0} requires ${1} to use this function"
    fi
}

# ======================================================================================
# ================================ ~ CLUSTERS ~ ========================================
# ======================================================================================


# --- download k3s install.sh ---
get_k3s() {
    has_bin curl
    curl https://get.k3s.io --output install-k3s.sh
    sudo chmod +x install-k3s.sh
}

# --- install k3s server or agent and run---
go_k3s() {
    _version="${1}"
    #_CHANNEL="${3:-testing}"
    #_type="${4:-server}"
    sudo INSTALL_K3S_version="${_version}" INSTALL_K3S_EXEC=server ./install-K3s.sh
    #sudo INSTALL_"${product}"_version="$_version" INSTALL_"${product}"_CHANNEL="$CHANNEL" INSTALL_"${product}"_EXEC="${type}" ./install-"${product}".sh
}

# --- download rke2 install.sh ---
get_rke2() {
    has_bin curl
    curl https://get.rke2.io --output install-rke2.sh
    sudo chmod +x install-rke2.sh
}

# --- start rke2 systemctl service type ---
go_rke2() {
    _type="${1:-server}"
    has_bin rke2
    sudo systemctl enable rke2-"${_type}" --now
}

# --- print to console current config file ---
get_figs() {
    _product="${1:-k3s}"
    printf '=========== %s config =========== \n' "${_product}"
    sudo cat /etc/rancher/"${_product}"/config.yaml;
}

# --- restore previously saved config file (from void function) ---
go_replay() {
    # after you've called void the tmp-confs directory is made with your previous config
    _product="${1:-k3s}"
    sudo mkdir -p /etc/rancher/"${_product}"/;
    sudo cp ~/tmp-confs/"${_product}"-config.yaml /etc/rancher/"${_product}"/config.yaml
}

# --- set KUBECONFIG environment variable ---
set_kubefig() {
    _product="${1:-k3s}"
    #consider the flag rootless instead of passing t or f
    _rootless="${2:-false}"
    if [ "${_rootless}" = true ]; then
        export KUBECONFIG=/home/"${USER}"/.kube/k3s.yaml
    else
        export KUBECONFIG=/etc/rancher/"${_product}"/"${_product}".yaml
        sudo chmod 644 /etc/rancher/"${_product}"/"${_product}".yaml
    fi
}

# --- quickly edit product config file ---
conf() {
    _product="${1:-k3s}"
    sudo vi /etc/rancher/"${_product}"/config.yaml
}

# --- prints out node token ---
get_token() {
    _product="${1:-k3s}"
    sudo cat /var/lib/rancher/"${_product}"/server/node-token
}

# --- killall uninstall all ---
void() {
    # sudo systemctl list-units | grep -i -e k3s -e rke2 ??? find whats installed - then just remove those instead of trying all
    mkdir ~/tmp-confs/
    sudo cp /etc/rancher/k3s/config.yaml ~/tmp-confs/k3s-config.yaml
    sudo cp /etc/rancher/rke2/config.yaml ~/tmp-confs/rke2-config.yaml
    sudo /usr/local/bin/rke2-agent-killall.sh
    sudo /usr/local/bin/rke2-agent-uninstall.sh
    sudo /usr/local/bin/k3s-agent-killall.sh
    sudo /usr/local/bin/k3s-agent-uninstall.sh
    sudo /usr/local/bin/rke2-killall.sh
    sudo /usr/local/bin/rke2-uninstall.sh
    sudo /usr/local/bin/k3s-killall.sh
    sudo /usr/local/bin/k3s-uninstall.sh
    sudo /usr/bin/rke2-killall.sh
    sudo /usr/bin/rke2-uninstall.sh
    sudo /usr/bin/k3s-killall.sh
    sudo /usr/bin/k3s-uninstall.sh
    # consider rm -rf /var/lib/rancher/
}

# --- list binaries in directory from product install ---
get_bins() {
    _product="${1:-k3s}"
    ls /var/lib/rancher/"${_product}"/data/current/bin/
    #consider _variable to find the embedded bin at known directory locations
    echo "/var/lib/rancher/k3s/data/current/bin OR /var/lib/rancher/rke2/data/current/bin"
}

# --- get performance profile from kubectl api ---
get_pprof() {
    has_bin curl
    # note this requires enable-pprof=true in config.yaml
    set -- "profile" "symbol" "trace?seconds=8" "cmdline"
    for id; do
        curl --insecure https://localhost:6443/debug/pprof/"${id}" > ~/"${id}".pprof
    done
        #back on localhost or wherever GoLang is installed 
        # run $ go tool pprof GENERATED_FILENAME to run various commands on the files like .PNG etc
        # trace uses $ go tool trace trace-outputfile view refresher - https://github.com/k3s-io/k3s/pull/5527 /// https://pkg.go.dev/net/http/pprof
}
#
# ======================================================================================
# ================================== ~ SONOBUOY ~ =======================================
# ======================================================================================

# --- download sonobuoy ---
get_sono() {
    has_bin wget
    _arch
    arch=$(if [ "$(uname -m)" = "x86_64" ]; then echo "amd64"; else echo "arm64"; fi)
    wget https://github.com/vmware-tanzu/sonobuoy/releases/download/v0.56.14/sonobuoy_0.56.14_linux_"${arch}".tar.gz
    sudo tar -xzf sonobuoy_0.56.14_linux_amd64.tar.gz -C /usr/local/bin
}

# --- start sonobuoy e2e conformance tests ---
go_sono() {
    _product="${1:-k3s}"
    _version
    _version=$(k3s --version | awk '{print $3}' | cut -c -7)
    has_bin sonobuoy
    #sonobuoy run --wait --kubeconfig /etc/rancher/"${product}"/"${product}".yaml --plugin https://raw.githubusercontent.com/vmware-tanzu/sonobuoy-plugins/master/cis-benchmarks/kube-bench-plugin.yaml --plugin https://raw.githubusercontent.com/vmware-tanzu/sonobuoy-plugins/master/cis-benchmarks/kube-bench-master-plugin.yaml
    sonobuoy run --wait --kubeconfig /etc/rancher/"${_product}"/"${_product}".yaml --kubernetes-version="${_version}" --mode=certified-conformance
}

# --- view sonobuoy results ---
sono_results() {
    _product="${1:-k3s}"
    has_bin sonobuoy
    _results=$(sonobuoy retrieve --kubeconfig /etc/rancher/"${_product}"/"${_product}".yaml)
    sonobuoy results "${_results}"    
}

# --- removes all docker images from the _cache ---
void_docker() {
    has_bin docker
    docker rmi "$(docker images -a -q)"
}
# ======================================================================================
# ================================== ~ RANCHER ~ =======================================
# ======================================================================================

# --- requires helm --- REWRITE WITH INSTALL.SH IF CHECKS FOR HELM --- https://github.com/k3s-io/k3s/blob/master/install.sh
make_ranch() {
    has_bin helm
    has_bin kubectl
    echo "need to adjust this to detect which binaries are already installed - modify the path based on their presences"
    echo "figure out all the steps here to setup a _rancher node to add downstream clusters to"
    sudo apt update && sudo apt upgrade -y
    wait
    helm repo add rancher-latest https://releases.rancher.com/server-charts/latest
    kubectl create namespace cattle-system
    helm repo add jetstack https://charts.jetstack.io
    helm repo update
    wait
    helm install cert-manager jetstack/cert-manager -n cert-manager --create-namespace --version v1.5.1
    wait
    echo "checking cert-manager pods.... "
    kubectl get pods -n cert-manager
    wait
    kubectl apply --validate=false -f https://github.com/jetstack/cert-manager/releases/download/v1.5.1/cert-manager.crds.yaml
    wait
    helm install rancher rancher-latest/rancher -n cattle-system --set hostname=break.qa.web --set rancherImageTag=v2.6.9 --version=v2.6.9 
    wait
    watch -n 7 kubectl -n cattle-system rollout status deploy/rancher
    kubectl port-forward "$(kubectl get pods --selector "app.kubernetes.io/name=traefik" --output=name -A)" 9000:9000 -A
}

# --- gets rancher password and dashboard url ---
get_ranch() {
    has_bin kubectl
    echo https://break.qa/dashboard/?setup="$(kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}')"
    kubectl get secret --namespace cattle-system bootstrap-secret -o go-template='{{.data.bootstrapPassword|base64decode}}{{ "\n" }}'
}

# --- forward the rancher ui to all interfaces ---
forward_ranch() {
    has_bin kubectl
    kubectl port-forward -n cattle-system svc/rancher 9944:443 --address='0.0.0.0'
}
#
#
# ======================================================================================
# ================================== ~ CONFIGURATIONS ~ ================================
# ======================================================================================

# --- set default configuration to edit ---
set_figs() {
    _product="${1:-k3s}"
    sudo mkdir -p /etc/rancher/"${_product}"/;
    #sudo cat <<EOF >> "${_product}"-config.yaml
    cat <<EOF >> "${_product}"-config.yaml
write-kubeconfig-mode: 644
debug: true
token: epicsalsa
cni: cilium
server:

profile: cis-1.6
selinux: true
#protect-kernel-defaults: true
#cluster-init: true
#disable: rke2-ingress-nginx
#pod-security-admission-config-file: "/etc/rancher/rke2/base-pss.yaml"

##EDIT these
node-ip: $(hostname -I)
#node-external-ip: IPV4,IPV6

##KUBELET ARGS 
#kubelet-arg:
#  - alsologtostderr=true
#  - feature-gates=MemoryManager=true
#  - kube-reserved=cpu=400m,memory=1Gi
#  - system-reserved=cpu=400m,memory=1Gi
#  - memory-manager-policy=Static
#  - reserved-memory=0:memory=2Gi

##SNAPSHOTS
#snapshot-compress: true
#etcd-snapshot-retention: 18
#etcd-snapshot-schedule-cron: "*/3 * * * *" #every 3 minutes

##VSPHERE
#private-registry: "/etc/rancher/rke2/registries.yaml"
#cloud-provider-name: "rancher-vsphere"
#cloud-provider-config: /home/rancher/vsphere.conf

#enable-pprof: true
#secrets-encryption: true
#kube-proxy-arg: "proxy-mode=ipvs"

##ETCD S3 CONFIG
#etcd-s3: true
#etcd-s3-bucket: "YOUR_BUCKET_NAME"
#etcd-s3-folder: "foldername ie 123 or 124 or 125"
#etcd-s3-region: "YOUR_REGION"
#etcd-s3-endpoint: "s3.us-west-2.amazonaws.com"
#etcd-s3-access-key: "YOUR_ACCESS_KEY"
#etcd-s3-secret-key: "YOUR_SECRET_KEY"

##DUALSTACK
#cluster-cidr: 10.42.0.0/16,2001:cafe:42:0::/56
#service-cidr: 10.43.0.0/16,2001:cafe:42:1::/112

#flannel-ipv6-masq: true
#disable: rke2-ingress-nginx

## SPLIT ROLES

##--etcd-only---
#disable-apiserver: true
#disable-controller-manager: true
#disable-scheduler: true
#node-taint:
#  - node-role.kubernetes.io/etcd:NoExecute

##--etcd-cp---
#node-taint:
#  - node-role.kubernetes.io/control-plane:NoSchedule
#  - node-role.kubernetes.io/etcd:NoExecute

##--etcd-worker---
#disable-apiserver: true
#disable-controller-manager: true
#disable-scheduler: true

##--cp-only---
#disable-etcd: true
#node-taint:
#  - node-role.kubernetes.io/control-plane:NoSchedule

##--cp-worker---
#disable-etcd: true

EOF
    sudo cp "${_product}"-config.yaml /etc/rancher/"${_product}"/config.yaml;
}

# --- set registries to look for bci hardened images ---
set_registries() {
    cat <<'EOF' >> registries.yaml
    mirrors:
    docker.io:
        rewrite:
        "^rancher/hardened-etcd(.*)": "bcibase/hardened-etcd$1"
        "^rancher/hardened-kubernetes(.*)": "bcibase/hardened-kubernetes$1"
        "^rancher/hardened-rke2-runtime(.*)": "bcibase/hardened-rke2-runtime$1"
        "^rancher/nginx-ingress-controller(.*)": "bcibase/nginx-ingress-controller$1"
        "^rancher/nginx-ingress-controller-chroot(.*)": "bcibase/nginx-ingress-controller-chroot$1"
        "^rancher/hardened-calico(.*)": "bcibase/hardened-calico$1"
        "^rancher/hardened-sriov-network-resources-injector(.*)": "bcibase/hardened-sriov-network-resources-injector$1"
        "^rancher/hardened-k8s-metrics-server(.*)": "bcibase/hardened-k8s-metrics-server$1"
        "^rancher/hardened-sriov-network-webhook(.*)": "bcibase/hardened-sriov-network-webhook$1"
        "^rancher/hardened-sriov-network-operator(.*)": "bcibase/hardened-sriov-network-operator$1"
        "^rancher/hardened-sriov-network-device-plugin(.*)": "bcibase/hardened-sriov-network-device-plugin$1"
        "^rancher/hardened-flannel(.*)": "bcibase/hardened-flannel$1"
        "^rancher/hardened-crictl(.*)": "bcibase/hardened-crictl$1"
        "^rancher/hardened-ib-sriov-cni(.*)": "bcibase/hardened-ib-sriov-cni$1"
        "^rancher/hardened-runc(.*)": "bcibase/hardened-runc$1"
        "^rancher/hardened-rke2-cloud-provider(.*)": "bcibase/hardened-rke2-cloud-provider$1"
        "^rancher/hardened-cni-plugins(.*)": "bcibase/hardened-cni-plugins$1"
        "^rancher/hardened-dns-node-cache(.*)": "bcibase/hardened-dns-node-cache$1"
        "^rancher/hardened-containerd(.*)": "bcibase/hardened-containerd$1"
        "^rancher/hardened-cluster-autoscaler(.*)": "bcibase/hardened-cluster-autoscaler$1"
        "^rancher/hardened-coredns(.*)": "bcibase/hardened-coredns$1"
        "^rancher/hardened-multus-cni(.*)": "bcibase/hardened-multus-cni$1"
        "^rancher/hardened-whereabouts(.*)": "bcibase/hardened-whereabouts$1"
EOF
    sudo cp registries.yaml /etc/rancher/rke2/registries.yaml
}

# --- vsphere in tree ---
set_vsphere() {
    cat <<'EOF' >> vsphere.conf
# vsphere.conf
Name:         vsphere-cloud-config
Namespace:    kube-system
Labels:       app.kubernetes.io/managed-by=Helm
              component=rancher-vsphere-cpi-cloud-controller-manager
              vsphere-cpi-infra=config
Annotations:  meta.helm.sh/release-name: rancher-vsphere-cpi
              meta.helm.sh/release-namespace: kube-system

Data
====
vsphere.yaml:
----
# Global properties in this section will be used for all specified vCenters unless overriden in VirtualCenter section.

[Global]
datacenters = "YOUR_DATA_CENTER"
insecure-flag = "1"
user = "YOUR_USER_NAME"
password = "YOUR_PASSWORD"
server = "YOUR_SERVER_NAME"
port = "YOUR_PORT"
secret-namespace: "kube-system" 
secret-name: "vsphere-cpi-creds"
 
[VirtualCenter "YOUR_SERVER_NAME"]
user = "YOUR_USER_NAME"
password = "YOUR_PASSWORD"
port = "YOUR_PORT"
datacenters = "YOUR_DATA_CENTER" 

[Workspace]
server = "YOUR_SERVER_NAME"
datacenters = "YOUR_DATA_CENTER"
default-datastore = "YOUR_DATA_STORE_URL"
resourcepool-path = "YOUR_RESOURCE_POOL_PATH"
folder = "YOUR_USERNAME"
EOF
}

# --- adding custom vsphere-values to the server manifests directory ---
set_vspheremanifests() {
    sudo mkdir -p /var/lib/rancher/rke2/server/manifests;
    cat <<'EOF' >> vsphere-values.yaml
# /var/lib/rancher/rke2/server/manifests/vsphere-values.yaml
apiversion: helm.cattle.io/v1
kind: HelmChartConfig
metadata:
  name: rancher-vsphere-cpi
  labels:
  namespace: kube-system
spec:
  valuesContent: |-
    vCenter:
      host: "YOUR_HOSTNAME"
      datacenters: "YOUR_DATA_CENTER"
      username: "YOUR_USERNAME"
      password: "YOUR_PASSWORD"
      credentialsSecret:
        generate: true
      labels:
        generate: true
        zone: "test-zone"
        region: "test-region"
    cloudControllerManager:
      nodeSelector:
        node-role.kubernetes.io/control-plane: "true"
---
apiversion: helm.cattle.io/v1
kind: HelmChartConfig
metadata:
  name: rancher-vsphere-csi
  namespace: kube-system
spec:
  valuesContent: |-
    vCenter:
      host: "YOUR_HOSTNAME"
      datacenters: "YOUR_DATA_CENTER"
      username: "YOUR_USERNAME"
      password: "YOUR_PASSWORD"
      clusterId: "YOUR_NODE_HOSTNAME"
      configSecret:
        configTemplate: |
         [Global]
         cluster-id = {{ required ".Values.vCenter.clusterId must be provided" (default .Values.vCenter.clusterId .Values.global.cattle.clusterId) | quote }}
         user = {{ .Values.vCenter.username | quote }}
         password = {{ .Values.vCenter.password | quote }}
         port = {{ .Values.vCenter.port | quote }}
         insecure-flag = {{ .Values.vCenter.insecureFlag | quote }}
         [VirtualCenter {{ .Values.vCenter.host | quote }}]
         datacenters = {{ .Values.vCenter.datacenters | quote }}
         [Labels]
         zone = "test-zone"
         region = "test-region"
    storageClass:
      datastoreURL: "YOUR_DATA_STORE_URL"
    csiController:
      nodeSelector:
        node-role.kubernetes.io/control-plane: "true"
EOF
    sudo cp vsphere-values.yaml /var/lib/rancher/rke2/server/manifests/vsphere-values.yaml
    cat <<'EOF' >> persistentVolume.yaml
apiversion: v1
kind: PersistentVolumeClaim
metadata:
  name: claim1
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: vsphere-csi-sc
  resources:
    requests:
      storage: 1Gi
EOF
    cat <<'EOF' >> useVolume-Workload.yaml
apiversion: "v1"
kind: "Pod"
metadata:
  name: "basic"
  labels:
    name: "basic"
spec:
  containers:
    - name: "basic"
      image: ranchertest/mytestcontainer:unprivileged
      ports:
        - containerPort: 8080
          name: "basic"
      volumeMounts:
        - mountPath: "/data"
          name: "pvol"
  volumes:
    - name: "pvol"
      persistentVolumeClaim:
        claimName: "claim1"
EOF
}

# --- creates a basic pod security standards file for k3s or rke2---
set_pss() {
    _product="${1:-k3s}"
    cat <<'EOF' >> base-pss.yaml
apiversion: apiserver.config.k8s.io/v1
kind: AdmissionConfiguration
plugins:
- name: PodSecurity
  configuration:
    apiversion: pod-security.admission.config.k8s.io/v1beta1
    kind: PodSecurityConfiguration
    defaults:
      enforce: "baseline"
      enforce-version: "latest"
    exemptions:
      usernames: []
      runtimeClasses: []
      namespaces: [kube-system, cis-operator-system, tigera-operator]
EOF
    sudo cp base-pss.yaml /etc/rancher/"${_product}"/base-pss.yaml
}

# --- sets up rhel 8-ish systems for rke2 ---
configure_rhel() {
  # Update the system packages
  sudo yum update -y

  # Install the dependencies for RKE2
  sudo yum install -y conntrack socat ebtables ethtool jq

  # Add the RKE2 RPM repository
  cat <<EOF | sudo tee /etc/yum.repos.d/rke2.repo
[rke2]
name=RKE2
baseurl=https://packages.rancher.com/rke2/rpm
enabled=1
gpgcheck=1
gpgkey=https://packages.rancher.com/gpg.key
EOF


  # Add the keyfile to fix NetworkManager
  sudo cp /etc/sysconfig/network-scripts/ifcfg-eth0 /etc/sysconfig/network-scripts/ifcfg-eth0.backup
  sudo sed -i '/^NM_CONTROLLED/d' /etc/sysconfig/network-scripts/ifcfg-eth0
  echo "NM_CONTROLLED=no" | sudo tee -a /etc/sysconfig/network-scripts/ifcfg-eth0 /dev/null

  # Disable nm-cloud-setup
  sudo systemctl disable nm-cloud-setup

}

# --- label nodes server and agent respectively for suc upgrade to run correctly ---
set_labels() {
    _product="${1:-k3s}"
    has_bin kubectl
    kubectl label node -l node-role.kubernetes.io/master==true "${_product}"-upgrade=server 
    kubectl label node -l node-role.kubernetes.io/master!=true "${_product}"-upgrade=agent
}

# --- print info logs when debug is enabled ---
get_logs() {
    _product="${1:-k3s}"
    _type="${2:-server}"
    sudo journalctl -xeu "${_product}"-"${_type}" -o json-pretty | grep -i -e message -e info
    # experiment with de-cluttering the normal pings to tunnel server etc
}

# --- rotate and vacuum logs ---
clean_logs() {
    sudo journalctl --rotate && sudo journalctl --vacuum-time=1s
}

# --- helper functions for logs ---
get_ulog() {
    sudo cat /var/log/ulog/syslogemu.log
}

# --- get systemctl status ---
get_status() {
    _product="${1:-k3s}"
    sudo systemctl status "${_product}"
}
#
# ======================================================================================
# ================================== ~ NETWORK TESTS ~ =================================
# ======================================================================================

# --- quickly list etcd cluster members ---
get_etcd() {
    _product="${1:-rke2}"
    has_bin etcdctl
     sudo ETCDCTL_API=3 etcdctl \
    --cert /var/lib/rancher/"${_product}"/server/tls/etcd/server-client.crt \
    --key /var/lib/rancher/"${_product}"/server/tls/etcd/server-client.key \
    --endpoints https://127.0.0.1:2379 \
    --cacert /var/lib/rancher/"${_product}"/server/tls/etcd/server-ca.crt \
    member list -w table
    ##   https://etcd.io/docs/v3.5/tutorials/how-to-deal-with-membership/
}

# --- quickly list manifest files ---
get_manifests() {
    _product="${1:-k3s}"
    _command="ls --color=auto /var/lib/rancher/${_product}/server/manifests"
    has_bin bash
    sudo --preserve-env=product bash -c "${_command}"
}

# --- quickly exec a shell in a pod ---
k_tty() {
    _namespace="{$1}"
    _podTarget="{$2}"
    has_bin kubectl
    kubectl exec -n "${_namespace}" --stdin --tty "${_podTarget}" -- /bin/bash
}

# --- quickly list any pods in any namespace in error or crashloop status ---
get_podcrash() {
    has_bin kubectl
    kubectl get pods -A | awk '$3 ~/CrashLoopBackOff/ {print $1 $3}'
    kubectl get pods -A | awk '$3 ~/Error/ {print $1 $3}'
}


# --- quickly list node taints ---
get_taints() {
    has_bin kubectl
    kubectl get nodes -o custom-columns=NAME:.metadata.name,TAINTS:.spec.taints
}
#

# --- check rke2 crictl images and versions ---
get_images() {
    _product="${1:-k3s}"
    case "${_product}" in
    rke2) sudo /var/lib/rancher/"${_product}"/bin/crictl --config /var/lib/rancher/"${_product}"/agent/etc/crictl.yaml ps
          sudo /var/lib/rancher/"${_product}"/bin/crictl --config /var/lib/rancher/"${_product}"/agent/etc/crictl.yaml images
        ;;
    k3s) 
        sudo k3s crictl ps
        sudo k3s crictl img ls
        ;;
    esac
}

# --- checks for the bci tag in rke2 containerd images ---
get_bci() {
    _product="${1:-rke2}"
    case "${_product}" in
    rke2) 
        has_bin rke2
        for id in $(sudo /var/lib/rancher/rke2/bin/crictl -r unix:///run/k3s/containerd/containerd.sock images | awk 'NR>1{print $3}'); do
                echo "The ID: ${id} "
                sudo /var/lib/rancher/rke2/bin/crictl -r unix:///run/k3s/containerd/containerd.sock inspecti "${id}" | grep bci
            done
        ;;
    k3s) 
        has_bin k3s
        for id in $(sudo k3s crictl -r unix:///run/k3s/containerd/containerd.sock images | awk 'NR>1{print $3}'); do 
            echo "The ID: ${id} "
            sudo k3s crictl -r unix:///run/k3s/containerd/containerd.sock inspecti "${id}" | grep bci 
        done
    ;;
    esac
}

# --- gets the ips of the pods in the provided namespace ---
get_podips() {
    _namespace="${1:-kube-system}"
    kubectl get pods -n "${_namespace}" -o jsonpath='{range .items[*]}{.metadata.name}{"    "}{.status.podIP}{"\n"}{end}'
}

# --- this is a work in progress but it gets the ips on the pods and pings the adjacent pods to check network connectivity this will likely go away in this form ---
ping_pods() {
    for pod in $(kubectl get pods -A | awk 'NR>1{print $2}')
        do   
            for ip in $(kubectl get pods -n kube-system "${pod}" -o yaml | grep -e "podIP: " | awk '{print $2}')
                do printf '%s' "${pod} \n"
                kubectl exec -n kube-system -it "${pod}" -- ping -c 5 "${ip}"
                done
        done
}

# --- less typing get ids of containers ---
get_containerids() {
    sudo ctr --address /run/k3s/containerd/containerd.sock --namespace k8s.io c ls
}

# --- less typing get containerd version ---
get_contd() {
    sudo /var/lib/rancher/rke2/bin/containerd --version
}

# --- take an adhoc etcd snapshot with less typing ---
take_etcd() {
    _folder="${1:-123}"
    sudo rke2 etcd-snapshot --s3 --s3-bucket=YOUR_BUCKET --s3-folder="${_folder}" --s3-region=YOUR_REGION --s3-access-key=YOUR_ACCESS_KEY --s3-secret-key=YOUR_SECRET_KEY
}
# ======================================================================================
# =========================== ~ SOMEDAY FUNCTIONS ~ ====================================
# ======================================================================================


# --- curl to pull down patch tests kubectl assert statements ---
get_tests() {
    has_bin git
    git clone https://github.com/rancher/ecm-distro-tools.git && cd ecm-distro-tools/qa/ || return
}

# --- future home of a to post or redirect kubectl api json results to an http endpoint ---
post_tests() {
    has_bin curl
    has_bin kubectl
    #curl -X POST -H "Content-type: application/json" -d '{"json":"json"}' http://localhost:8080
    #_YOUR_PUB_KEY="${1:-${HOME}/.ssh/id_rsa.pub}"
    echo "curl -X POST github.api thing"
    kubectl cluster-info dump > dump.json
}
#
# ======================================================================================
# =========================== ~ CONFIGURATIONS ~ =======================================
# ======================================================================================

# --- generates a github comment template to cat to console and copy to paste in github for the issue ---
get_report() {
    _product="${1:-k3s}"
    cat << EOF >> validation_template.md
<!-- Thanks for using this template. Comment like this will be hidden. Enjoy! -->
<!-- Make sure you remove any sensitive information and change IPs before sharing. -->
##Environment Details
COMMIT=${COMMIT}
VERSION=${VERSION}

*Infrastructure*
- [X] Cloud
- [ ] Hosted 

*Node(s) CPU architecture, OS, and version:*

$(uname -rpos) 
$(grep /etc/os-release -i -e pretty)
 
*Cluster Configuration:*

$(kubectl get nodes) 

*Config.yaml:*

$(sudo cat /etc/rancher/"${_product}"/config.yaml)

<details>
<summmary><h4> YOUR_REPRODUCED_RESULTS_HERE </h4></summary>

<!-- Provide the command to install "${_product}" -->

curl https://get.${_product}.io --output install-"${_product}".sh
sudo chmod +x install-"${_product}".sh
sudo groupadd --system etcd && sudo useradd -s /sbin/nologin --system -g etcd etcd
sudo modprobe ip_vs_rr
sudo modprobe ip_vs_wrr
sudo modprobe ip_vs_sh
sudo printf "on_oovm.panic_on_oom=0 \nvm.overcommit_memory=1 \nkernel.panic=10 \nkernel.panic_ps=1 \nkernel.panic_on_oops=1 \n" > ~/60-rke2-cis.conf
sudo cp 60-rke2-cis.conf /etc/sysctl.d/
sudo systemctl restart systemd-sysctl


"$(history)"

**Results:**

</details>

<details>
<summmary><h4> YOUR_VALIDATION_RESULTS_HERE </h4></summary>
**Validated with **
 
## Validation Steps
 
- Install "${_product}":
 
 
**Additional context / logs:**
</details>  
EOF
}
#

# --- creates etcduser account on system and also kernel params in rke2 ---
set_etcduser() {
    sudo groupadd --system etcd && sudo useradd -s /sbin/nologin --system -g etcd etcd
}

# --- set kernel params for hardening ---
set_harden() {
    _product="${1:-k3s}"
    case "${_product}" in
    rke2) printf "on_oovm.panic_on_oom=0 \nvm.overcommit_memory=1 \nkernel.panic=10 \nkernel.panic_ps=1 \nkernel.panic_on_oops=1 \nkernel.keys.root_maxbytes=25000000" > ~/60-rke2-cis.conf
          sudo cp 60-rke2-cis.conf /etc/sysctl.d/
          sudo sysctl -p /etc/sysctl.d/60-rke2-cis.conf
            ;;
    k3s) printf "on_oovm.panic_on_oom=0 \nvm.overcommit_memory=1 \nkernel.panic=10 \nkernel.panic_ps=1 \nkernel.panic_on_oops=1 \nkernel.keys.root_maxbytes=25000000" > ~/90-kubelet.conf
         sudo cp 90-kubelet.conf /etc/sysctl.d/
         sudo sysctl -p /etc/sysctl.d/90-kubelet.conf
            ;;
    esac
    sudo modprobe ip_vs_rr
    sudo modprobe ip_vs_wrr
    sudo modprobe ip_vs_sh
    wait
    sudo systemctl restart systemd-sysctl
}

# --- create arbitrary nats server config ---
set_nats() {
cat <<'EOF' >> nats.conf
port: 4222
net: '0.0.0.0'
authorization: {
  users: [
    {user: "k3s", password: "k3smighty"},
    {user: "rke2", password: "rke2mighty"}
  ]
}
EOF
sudo mkdir -p /srv/nats/
sudo cp nats-config.yaml /srv/nats/nats.conf
cat <<'EOF' >> nats.service
[Unit]
Description=NATS jetstream messaging server

[Service]
ExecStart=/usr/bin/nats-server -js -c /srv/nats/nats.config
User=nats
Restart=on-failure

[Install]
WantedBy=multi-user.target
EOF
sudo cp nats.service /etc/systemd/system/nats.service
sudo adduser --system --group --no-create-home --shell /bin/false nats
sudo systemctl enable nats --now
}

get_rootless() {
    if [ "$USER" != "ubuntu" ]; then
        printf "I haven't mapped this process out on different OS's yet."
        get_help get_rootless
    elif [ ! "$(command -v newuidmap)" ]; then
        printf "You'll need to install uidmap ie: \n sudo apt install uidmap\n"
    else
        wget https://raw.githubusercontent.com/k3s-io/k3s/master/k3s-rootless.service
        mkdir -p /home/ubuntu/.config/systemd/user/
        cp k3s-rootless.service /home/ubuntu/.config/systemd/user/k3s-rootless.service
        printf "[Service]\nDelegate=cpu cpuset io memory pids\n" > delegate.conf
        printf "net.ipv4.ip_forward=1\nnet.ipv6.conf.all.forwarding=1\n" | sudo tee -a /etc/sysctl.conf /dev/null
        sudo mkdir -p /etc/systemd/system/user@.service.d/
        sudo cp ~/delegate.conf /etc/systemd/system/user@.service.d/delegate.conf
        sudo tee -a /etc/modules <<EOF
fuse
tun
tap 
bridge
br_netfilter 
veth
ip_tables
ip6_tables
iptable_nat
ip6table_nat
iptable_filter
ip6table_filter
nf_tables
x_tables
xt_MASQUERADE
xt_addrtype
xt_comment
xt_conntrack
xt_mark
xt_multiport
xt_nat
xt_tcpudp
EOF
        #printf "systemd.unified_cgroup_hierarchy=1" | sudo tee -a /etc/default/grub > /dev/null 
        #sed no worky
        #sed -i 's/GRUB_CMDLINE_LINUX_DEFAULT="[^"]*/& systemd.unified_cgroup_hierarchy=1/' /etc/default/grub
        #sudo sysctl --system
        #systemctl --user daemon-reload
        #sudo update-grub
        printf "you'll need to update /etc/default/grub and add systemd.unified_cgroup_hierarchy=1 to GRUB_CMDLINE_LINUX_DEFAULT=""\n"
        printf "You'll need to update your packages then install uidmap and reboot to finish the setup.\n"
    fi
}
# ======================================================================================
# =========================== ~ GET TOOLS ~ ============================================
# ======================================================================================

# --- helper to print functions in this file ---
get_help() {
    _info="${1:-function}"
    _no_of_lines="${2:-6}"
    grep ~/.bashrc -i -e "${_info}" -A "${_no_of_lines}"
}

# --- install helm to the node ---
get_helm() {
    has_bin curl
    sudo curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
    sudo chmod +x get_helm.sh
    sudo ./get_helm.sh
}

# --- install docker ---
get_docker() {
    has_bin curl
    curl -fsSL https://get.docker.com -o get-docker.sh && sudo chmod +x get-docker.sh
    sudo ./get-docker.sh
    has_bin docker
    sudo systemctl enable docker --now
}

# --- install wireguard ---
get_wireguard() {
    printf "use your package manager to update && upgrade, then install wireguard \n note there are more steps to get wireguard working on SLES and SLEM"
}

# --- install etcdctl ---
get_etcdctl() {
    has_bin curl
    _etcd_version=v3.5.0
    # choose either URL
    # GOOGLE_URL=https://storage.googleapis.com/etcd
    _github_url=https://github.com/etcd-io/etcd/releases/download
    _download_url=${_github_url}

    rm -f /tmp/etcd-${_etcd_version}-linux-amd64.tar.gz
    rm -rf /tmp/etcd-download-test && mkdir -p /tmp/etcd-download-test
    curl -L ${_download_url}/${_etcd_version}/etcd-${_etcd_version}-linux-amd64.tar.gz -o /tmp/etcd-${_etcd_version}-linux-amd64.tar.gz
    tar xzvf /tmp/etcd-${_etcd_version}-linux-amd64.tar.gz -C /tmp/etcd-download-test --strip-components=1
    rm -f /tmp/etcd-${_etcd_version}-linux-amd64.tar.gz
    /tmp/etcd-download-test/etcd --version
    /tmp/etcd-download-test/etcdctl version
    /tmp/etcd-download-test/etcdutl version
    sudo cp /tmp/etcd-download-test/etcdctl /usr/bin/etcdctl
    etcdctl version
}

# --- install zerotier vpn ---
get_zt() {
    has_bin curl
    curl -s https://install.zerotier.com | sudo bash
    wait
    sudo zerotier-cli join YOUR_ZT_NETWORK_ID
}

# --- install nats.io ---
get_nats() {
    has_bin wget
    wget https://github.com/nats-io/nats-server/releases/download/v2.8.2/nats-server-v2.8.2-linux-amd64.tar.gz
    sudo tar -zxf nats-server-v2.8.2-linux-amd64.tar.gz
    sudo cp nats-server-v2.8.2-linux-amd64/nats-server /usr/bin/
    nats-server -v
}

# --- install krew plugin for kubectl ---
get_krew() {
    has_bin git
    has_bin kubectl
    (
  set -x; cd "$(mktemp -d)" &&
  OS="$(uname | tr '[:upper:]' '[:lower:]')" &&
  ARCH="$(uname -m | sed -e 's/x86_64/amd64/' -e 's/\(arm\)\(64\)\?.*/\1\2/' -e 's/aarch64$/arm64/')" &&
  KREW="krew-${OS}_${ARCH}" &&
  curl -fsSLO "https://github.com/kubernetes-sigs/krew/releases/latest/download/${KREW}.tar.gz" &&
  tar zxvf "${KREW}.tar.gz" &&
  ./"${KREW}" install krew
)
}

# --- install krew plugin for kubectl ---
get_kuttl() {
    has_bin kubectl
    kubectl krew install kuttl
}

# --- install akri into the cluster using helm ---
get_akri() {
    has_bin helm
    _akri_helm_crictl_configuration="--set kubernetesDistro=k3s"
    helm repo add akri-helm-charts https://project-akri.github.io/akri/
    helm install akri akri-helm-charts/akri "${_akri_helm_crictl_configuration}"
}
# ======================================================================================
# ================================== ~ CAPTAINS ~ ======================================
# ======================================================================================

# --- check CI for releases ---
get_ci() {
    #requires drone logins :/ 
    printf "https://drone-publish.rancher.io/rancher/rke2  or https://drone-publish.k3s.io/k3s-io/k3s"
}

# --- check DockerHub system agent installers and upgrade images ---
get_artifacts() {
    _product="${1:-k3s}"
    _branch="${2:-v1.22}"
    has_bin curl
    has_bin jq 
        printf "===== System Agent Installers ===== \n"
        curl -L -s "https://registry.hub.docker.com/v2/repositories/rancher/system-agent-installer-${_product}/tags?page_size=300" | jq -r ".results[].name" | sort --version-sort | grep -i -e "${_branch}" | tail -n 5 # > system-agent-installers.txt
        printf "===== Upgrade Images ===== \n"
        curl -L -s "https://registry.hub.docker.com/v2/repositories/rancher/${_product}-upgrade/tags?page_size=300" | jq -r ".results[].name" | sort --version-sort | grep -i -e "${_branch}" | tail -n 5 #  > upgrade-images.txt
        printf '===== %s Images ===== \n' "${_product}"
    case "${_product}" in
    rke2)
        curl -s -H "Accept: application/vnd.github+json" https://api.github.com/repos/rancher/rke2/releases | jq '.[].tag_name' | sort --version-sort | grep -i -e "${_branch}" | tail -n 1
        # diff --color -s --suppress-common-lines system-agent-installers.txt upgrade-images.txt
    ;;
    k3s)
        curl -s -H "Accept: application/vnd.github+json" https://api.github.com/repos/k3s-io/k3s/releases | jq '.[].tag_name' | sort --version-sort | grep -i -e "${_branch}" | tail -n 1
        # diff --color -s --suppress-common-lines system-agent-installers.txt upgrade-images.txt
    ;;
    esac
}

# ======================================================================================
# ================================== ~ GITHUB ~ =======================================
# ======================================================================================

# --- list issues in the github repos using the gh cli --- 
 ghls() {
	_product="${1:-k3s}"
    _user="${2:-YOUR_GITHUB_USERNAME}"
    has_bin gh
    case $_product in
    qa) gh issue ls -R rancher/qa-tasks -a "${_user}" ;;
	rke2) gh issue ls -R rancher/rke2 -a "${_user}" ;;
	k3s) gh issue ls -R k3s-io/k3s -a "${_user}" ;;
	na)
	  printf "K3S-ISSUES---------------------------------------"
	  gh issue ls -R k3s-io/k3s 
	  printf "\nRKE2-ISSUES------------------------------------"
	  gh issue ls -R rancher/rke2
      printf "\nQA-ISSUES---------------------------------------"
      gh issue ls -R rancher/qa-tasks
	  ;;
	esac
	}

# --- get github issue comments ---
 ghcom() {
	_product="${1:-k3s}"	
	_issue="${2}"
    has_bin gh
    case $_product in
	rke2)
	  gh issue view -c "${_issue}" -R rancher/rke2
	  ;;	
	k3s)
	  gh issue view -c "${_issue}" -R k3s-io/k3s
	  ;;
    qa)
      gh issue view -c "${_issue}" -R rancher/qa-tasks
      ;;
	esac
	}

# --- list issues closed in the last n days for the milestone ---
ghclosed() {
    _product="${1:-k3s}"
    _days="${2:-7}"
    _date
    has_bin gh
    date=$(date -v -"$_days"d +%F)
    _milestone="${3:-v1.25.3+k3s1}"
    case $_product in
    rke2)
      gh search issues --repo rancher/rke2 --closed \>"$date" --milestone "${_milestone}"
      ;;
    k3s)
        gh search issues --repo k3s-io/k3s --closed \>"$date" --milestone "${_milestone}"
        ;;
    qa)
        gh search issues --repo rancher/qa-tasks --closed \>"$date"
        ;;
    esac
    }

# --- list issues in milestone ---
ghmile() {
    _milestone="${1}"
    _product="${2:-k3s}"
    has_bin gh
    case $_product in
    rke2)
        gh issue list --milestone "${_milestone}" -R rancher/rke2
        ;;
    k3s)
        gh issue list --milestone "${_milestone}" -R k3s-io/k3s
        ;;
    esac
}

# ======================================================================================
# ================================== ~ ALIASES ~ =======================================
# ======================================================================================
#
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin:/snap/bin:/var/lib/rancher/k3s/bin:/var/lib/rancher/rke2/bin:/usr/local/bin/go/bin:/opt/rke2/bin/:${HOME}/.krew/bin
# enable color support of ls and also add handy aliases
if [ -x /usr/bin/dircolors ]; then
    test -r ~/.dircolors && eval "$(dircolors -b ~/.dircolors)" || eval "$(dircolors -b)"
    alias ls='ls --color=auto'
    alias dir='dir --color=auto'
    alias vdir='vdir --color=auto'
    alias grep='grep --color=auto'
    alias fgrep='fgrep --color=auto'
    alias egrep='egrep --color=auto'
fi
alias alert='notify-send --urgency=low -i "$([ $? = 0 ] && echo terminal || echo error)" "$(history|tail -n1|sed -e '\''s/^\s*[0-9]\+\s*//;s/[;&|]\s*alert$//'\'')"'
alias ll="ls -lahr "
alias eventz="kubectl get events -A "
alias k="kubectl "
alias kl="kubectl logs "
alias kg="kubectl get "
alias kgs="kubectl get svc "
alias kge="kubectl get endpoints "
alias kgn="kubectl get nodes "
alias kgp="kubectl get pods "
alias kga="kubectl get all -A -o wide "
alias w2="watch -n 3 "
alias sono="sonobuoy "
alias kd="kubectl describe "
alias srz="source ~/.bashrc"
alias ll='ls -alF'
alias la='ls -A'
alias l='ls -CF'
#
cat << "EOF"
--------------------------------
--------------@@@@--------------
--------------@@@@--------------█████████████████████████████████████
--------------@@@@--------------██,,,████,,,,█,,,,,,,,,████,,,,,,,███
--------------@@@@--------------██,,,██,,,,████████,,,,██,,,██████,,█
--------------@@@@--------------██,,,,,,,███████,,,,███████,,,███████
--------------------------------██,,,,,,,,██████████,,,███████,,,,███
----------@@&-----&@@-----------██,,,███,,,███,,,███,,,█,,███████,,,█
-------@@@@@@----&@@@@@@--------██,,,████,,,,██,,,,,,,████,,,,,,,,███
---@@@@@@@-----------@@@@@@@----█████████████████████████████████████
---@@%-------------------&@@----
--------------------------------             QA-Toolbox
--------------------------------
EOF
